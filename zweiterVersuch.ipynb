{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"zweiterVersuch.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"sFaWSaFmchJ5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":128},"executionInfo":{"status":"ok","timestamp":1593601299892,"user_tz":-120,"elapsed":17736,"user":{"displayName":"Jannis Speer","photoUrl":"","userId":"06809078632069073050"}},"outputId":"98fb0342-58bb-4cc8-ad3e-ab9db1c22097"},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","root_path1 = 'gdrive/My Drive/MLforphysicist'\n","root_path2 = 'gdrive/My\\ Drive/MLforphysicist'  #change dir to your project folder\n","repo_path1 = root_path1+\"/frcnn-from-scratch-with-keras-master\"\n","repo_path2 = root_path2+\"/frcnn-from-scratch-with-keras-master\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r4DM2SNMefdt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593601411410,"user_tz":-120,"elapsed":129245,"user":{"displayName":"Jannis Speer","photoUrl":"","userId":"06809078632069073050"}},"outputId":"137fce1a-c9c6-4c72-c886-3f29c0873219"},"source":["requirement_path = repo_path2+\"/requirements.txt\"\n","print(requirement_path)\n","print(type(requirement_path))\n","\n","!pip install -r {requirement_path}\n","!pip install tensorflow==1.15.0\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["gdrive/My\\ Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/requirements.txt\n","<class 'str'>\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from -r gdrive/My Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/requirements.txt (line 1)) (2.10.0)\n","Collecting Keras==2.2.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n","\u001b[K     |████████████████████████████████| 317kB 7.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r gdrive/My Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/requirements.txt (line 3)) (1.18.5)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r gdrive/My Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/requirements.txt (line 4)) (4.1.2.30)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r gdrive/My Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/requirements.txt (line 5)) (0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->-r gdrive/My Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/requirements.txt (line 1)) (1.12.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4->-r gdrive/My Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/requirements.txt (line 2)) (3.13)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4->-r gdrive/My Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/requirements.txt (line 2)) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4->-r gdrive/My Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/requirements.txt (line 2)) (1.1.2)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4->-r gdrive/My Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/requirements.txt (line 2)) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r gdrive/My Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/requirements.txt (line 5)) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r gdrive/My Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/requirements.txt (line 5)) (0.15.1)\n","Installing collected packages: Keras\n","  Found existing installation: Keras 2.3.1\n","    Uninstalling Keras-2.3.1:\n","      Successfully uninstalled Keras-2.3.1\n","Successfully installed Keras-2.2.4\n","Collecting tensorflow==1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n","\u001b[K     |████████████████████████████████| 412.3MB 44kB/s \n","\u001b[?25hCollecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 33.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.10.0)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 41.0MB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.2.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.30.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (47.3.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.6.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.1.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=aab92059087a66f000b65459f567bf04315066d55bf243b3dec3e32c896712fa\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorflow-estimator, tensorboard, gast, tensorflow\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","  Found existing installation: tensorboard 2.2.2\n","    Uninstalling tensorboard-2.2.2:\n","      Successfully uninstalled tensorboard-2.2.2\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow 2.2.0\n","    Uninstalling tensorflow-2.2.0:\n","      Successfully uninstalled tensorflow-2.2.0\n","Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LaNsMqMXr-W3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1593601417390,"user_tz":-120,"elapsed":135219,"user":{"displayName":"Jannis Speer","photoUrl":"","userId":"06809078632069073050"}},"outputId":"c946d3a7-ae54-4349-f598-d9d440ff29e8"},"source":["\n","#import TF  \n","import tensorflow as tf\n","import keras\n","from platform import python_version\n","print(\"Tensorflow version\", tf.__version__)\n","print(\"keras version\", keras.__version__)\n","print(\"Python version =\",python_version())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Tensorflow version 1.15.0\n","keras version 2.2.4\n","Python version = 3.6.9\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NwgYlHSdCR3S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":528},"executionInfo":{"status":"ok","timestamp":1593601418795,"user_tz":-120,"elapsed":136621,"user":{"displayName":"Jannis Speer","photoUrl":"","userId":"06809078632069073050"}},"outputId":"cfb2dc71-beef-4596-fbaf-a1fd7edd5004"},"source":["from tensorflow.python.client import device_lib\n","\n","device_lib.list_local_devices()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 9869776412983697299, name: \"/device:XLA_CPU:0\"\n"," device_type: \"XLA_CPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 15567066046832069296\n"," physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n"," device_type: \"XLA_GPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 15454237308311223651\n"," physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 11330115994\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 4185372108605446573\n"," physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"r_JFIHlPCLC6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593601418796,"user_tz":-120,"elapsed":136620,"user":{"displayName":"Jannis Speer","photoUrl":"","userId":"06809078632069073050"}}},"source":[""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cV5fIQngiSl3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593602095558,"user_tz":-120,"elapsed":813377,"user":{"displayName":"Jannis Speer","photoUrl":"","userId":"06809078632069073050"}},"outputId":"7268ffae-979b-487a-afa9-c9836b14c2f4"},"source":["#python train_rpn.py --network vgg16 -o simple -p ./dataset.txt\n","#train_path = repo_path2+\"/train_frcnn.py\"\n","data_path = root_path2+\"/TEST.txt\"\n"," \n","train_path = repo_path2+\"/train_rpn.py\"\n","print(train_path)\n","#data_path = root_path2+\"/firsttrain.txt\"\n","print(data_path)\n","preweight_path = root_path2+\"/weights/vgg16_weights_tf_dim_ordering_tf_kernels.h5\"\n","\n","!python {train_path} --network vgg -o simple -p {data_path} --input_weight_path {preweight_path}"],"execution_count":5,"outputs":[{"output_type":"stream","text":["gdrive/My\\ Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/train_rpn.py\n","gdrive/My\\ Drive/MLforphysicist/TEST.txt\n","Using TensorFlow backend.\n","WARNING:tensorflow:From gdrive/My Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/train_rpn.py:28: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From gdrive/My Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/train_rpn.py:30: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2020-07-01 11:03:45.900213: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2020-07-01 11:03:45.905606: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-07-01 11:03:45.905866: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b36bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-07-01 11:03:45.905900: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-07-01 11:03:45.908053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-07-01 11:03:45.956240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-01 11:03:45.957095: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b36d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-07-01 11:03:45.957130: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2020-07-01 11:03:45.957321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-01 11:03:45.958030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-07-01 11:03:45.958373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-07-01 11:03:45.959668: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-07-01 11:03:45.961145: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-07-01 11:03:45.961478: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-07-01 11:03:45.963181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-07-01 11:03:45.964725: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-07-01 11:03:45.970794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-01 11:03:45.970942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-01 11:03:45.971829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-01 11:03:45.972521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-07-01 11:03:45.972613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-07-01 11:03:45.974011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-07-01 11:03:45.974045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-07-01 11:03:45.974063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-07-01 11:03:45.974232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-01 11:03:45.975014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-01 11:03:45.975754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","Parsing annotation files\n","{'A': 11}\n","Training images per class:\n","{'A': 11, 'bg': 0}\n","Num classes (including bg) = 2\n","Config has been written to config.pickle, and can be loaded when testing to ensure correct results\n","Num train samples 9\n","Num val samples 2\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n","\n","loading weights from gdrive/My Drive/MLforphysicist/weights/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","loaded weights!\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None, None, 3 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, None, None, 6 1792        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, None, None, 6 36928       block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_pool (MaxPooling2D)      (None, None, None, 6 0           block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block2_conv1 (Conv2D)           (None, None, None, 1 73856       block1_pool[0][0]                \n","__________________________________________________________________________________________________\n","block2_conv2 (Conv2D)           (None, None, None, 1 147584      block2_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv1 (Conv2D)           (None, None, None, 2 295168      block2_pool[0][0]                \n","__________________________________________________________________________________________________\n","block3_conv2 (Conv2D)           (None, None, None, 2 590080      block3_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv3 (Conv2D)           (None, None, None, 2 590080      block3_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block4_conv1 (Conv2D)           (None, None, None, 5 1180160     block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","block4_conv2 (Conv2D)           (None, None, None, 5 2359808     block4_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block4_conv3 (Conv2D)           (None, None, None, 5 2359808     block4_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, None, None, 5 0           block4_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block5_conv1 (Conv2D)           (None, None, None, 5 2359808     block4_pool[0][0]                \n","__________________________________________________________________________________________________\n","block5_conv2 (Conv2D)           (None, None, None, 5 2359808     block5_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block5_conv3 (Conv2D)           (None, None, None, 5 2359808     block5_conv2[0][0]               \n","__________________________________________________________________________________________________\n","rpn_conv1 (Conv2D)              (None, None, None, 5 2359808     block5_conv3[0][0]               \n","__________________________________________________________________________________________________\n","rpn_out_class (Conv2D)          (None, None, None, 9 4617        rpn_conv1[0][0]                  \n","__________________________________________________________________________________________________\n","rpn_out_regress (Conv2D)        (None, None, None, 3 18468       rpn_conv1[0][0]                  \n","==================================================================================================\n","Total params: 17,097,581\n","Trainable params: 17,097,581\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Starting training\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Epoch 1/50\n","2020-07-01 11:04:29.685562: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-01 11:04:33.776661: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","1000/1000 [==============================] - 616s 616ms/step - loss: 0.4699 - rpn_out_class_loss: 0.3303 - rpn_out_regress_loss: 0.1396 - val_loss: 0.0012 - val_rpn_out_class_loss: 1.4052e-04 - val_rpn_out_regress_loss: 0.0011\n","Epoch 2/50\n","  21/1000 [..............................] - ETA: 9:32 - loss: 0.0060 - rpn_out_class_loss: 6.8680e-07 - rpn_out_regress_loss: 0.0060Traceback (most recent call last):\n","  File \"gdrive/My Drive/MLforphysicist/frcnn-from-scratch-with-keras-master/train_rpn.py\", line 241, in <module>\n","    steps_per_epoch=options.epoch_length, callbacks=callback, validation_steps=100)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1418, in fit_generator\n","    initial_epoch=initial_epoch)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\", line 217, in fit_generator\n","    class_weight=class_weight)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1217, in train_on_batch\n","    outputs = self.train_function(ins)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\n","    return self._call(inputs)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\n","    fetched = self._callable_fn(*array_vals)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n","    run_metadata_ptr)\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mLFQBi5T1Foy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593602097410,"user_tz":-120,"elapsed":815227,"user":{"displayName":"Jannis Speer","photoUrl":"","userId":"06809078632069073050"}},"outputId":"5b8b85e5-e763-4a10-8f0e-972b820910aa"},"source":["!ls"],"execution_count":6,"outputs":[{"output_type":"stream","text":["config.pickle  gdrive  models  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tttSCHuakdfl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593602099250,"user_tz":-120,"elapsed":817066,"user":{"displayName":"Jannis Speer","photoUrl":"","userId":"06809078632069073050"}},"outputId":"c04cff9a-1a60-469e-8fb2-dcd62a9bc005"},"source":["!ls models/"],"execution_count":7,"outputs":[{"output_type":"stream","text":["rpn\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eSqK9cEQmsVE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593602101149,"user_tz":-120,"elapsed":818963,"user":{"displayName":"Jannis Speer","photoUrl":"","userId":"06809078632069073050"}},"outputId":"eea04116-14fb-4293-cc1e-a1adea558106"},"source":["!ls /content/\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["config.pickle  gdrive  models  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n1-kutsXkLA1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":108},"executionInfo":{"status":"ok","timestamp":1593602103807,"user_tz":-120,"elapsed":821619,"user":{"displayName":"Jannis Speer","photoUrl":"","userId":"06809078632069073050"}},"outputId":"448e3851-150f-4e89-d6a7-d2809e88b33e"},"source":["!ls -l"],"execution_count":9,"outputs":[{"output_type":"stream","text":["total 16\n","-rw-r--r-- 1 root root  842 Jul  1 11:04 config.pickle\n","drwx------ 4 root root 4096 Jul  1 11:01 gdrive\n","drwxr-xr-x 3 root root 4096 Jul  1 11:03 models\n","drwxr-xr-x 1 root root 4096 Jun 26 16:26 sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xbqkh0ONkZyj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593602125449,"user_tz":-120,"elapsed":2677,"user":{"displayName":"Jannis Speer","photoUrl":"","userId":"06809078632069073050"}}},"source":["!ls models/rpn/"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ng3u5Eslkg6J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1593602107872,"user_tz":-120,"elapsed":825681,"user":{"displayName":"Jannis Speer","photoUrl":"","userId":"06809078632069073050"}},"outputId":"5e8636db-d45d-46dc-bcb4-27c256d63d38"},"source":["!ls sample_data/"],"execution_count":11,"outputs":[{"output_type":"stream","text":["anscombe.json\t\t      mnist_test.csv\n","california_housing_test.csv   mnist_train_small.csv\n","california_housing_train.csv  README.md\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_nSr-X6zIT3i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":781},"executionInfo":{"status":"ok","timestamp":1593602826890,"user_tz":-120,"elapsed":3502,"user":{"displayName":"Jannis Speer","photoUrl":"","userId":"06809078632069073050"}},"outputId":"d4b83eef-d474-4d02-a830-6324e69d091e"},"source":["!git\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n","           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n","           [-p | --paginate | --no-pager] [--no-replace-objects] [--bare]\n","           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n","           <command> [<args>]\n","\n","These are common Git commands used in various situations:\n","\n","start a working area (see also: git help tutorial)\n","   clone      Clone a repository into a new directory\n","   init       Create an empty Git repository or reinitialize an existing one\n","\n","work on the current change (see also: git help everyday)\n","   add        Add file contents to the index\n","   mv         Move or rename a file, a directory, or a symlink\n","   reset      Reset current HEAD to the specified state\n","   rm         Remove files from the working tree and from the index\n","\n","examine the history and state (see also: git help revisions)\n","   bisect     Use binary search to find the commit that introduced a bug\n","   grep       Print lines matching a pattern\n","   log        Show commit logs\n","   show       Show various types of objects\n","   status     Show the working tree status\n","\n","grow, mark and tweak your common history\n","   branch     List, create, or delete branches\n","   checkout   Switch branches or restore working tree files\n","   commit     Record changes to the repository\n","   diff       Show changes between commits, commit and working tree, etc\n","   merge      Join two or more development histories together\n","   rebase     Reapply commits on top of another base tip\n","   tag        Create, list, delete or verify a tag object signed with GPG\n","\n","collaborate (see also: git help workflows)\n","   fetch      Download objects and refs from another repository\n","   pull       Fetch from and integrate with another repository or a local branch\n","   push       Update remote refs along with associated objects\n","\n","'git help -a' and 'git help -g' list available subcommands and some\n","concept guides. See 'git help <command>' or 'git help <concept>'\n","to read about a specific subcommand or concept.\n"],"name":"stdout"}]}]}